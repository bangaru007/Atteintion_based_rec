{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":4508,"sourceType":"datasetVersion","datasetId":138},{"sourceId":77759,"sourceType":"datasetVersion","datasetId":339},{"sourceId":230378,"sourceType":"datasetVersion","datasetId":98156},{"sourceId":7017682,"sourceType":"datasetVersion","datasetId":4035037},{"sourceId":6375455,"sourceType":"kernelVersion"},{"sourceId":22781910,"sourceType":"kernelVersion"}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":5,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/bangarurajesh/attnetion-based-rec-sys?scriptVersionId=208973393\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"id":"e689bc35-851b-40ce-a681-891a5c47adc6","cell_type":"markdown","source":"## data.py","metadata":{}},{"id":"2f9ae033-f336-496c-ab08-602ca2abe6dd","cell_type":"code","source":"data_dir = '/kaggle/input/movielens100k-original'\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T08:03:12.568119Z","iopub.execute_input":"2024-11-22T08:03:12.568519Z","iopub.status.idle":"2024-11-22T08:03:12.578357Z","shell.execute_reply.started":"2024-11-22T08:03:12.568482Z","shell.execute_reply":"2024-11-22T08:03:12.577132Z"}},"outputs":[],"execution_count":1},{"id":"a323fa10-35ff-4c66-bed8-710c6ab3b7e8","cell_type":"code","source":"import pandas as pd\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.preprocessing import LabelEncoder\n\ndef load_data(data_dir):\n    # Load ratings\n    ratings = pd.read_csv(f'{data_dir}/ratings.dat', sep='::', header=None, engine='python',\n                          names=['user_id', 'movie_id', 'rating', 'timestamp'], encoding='ISO-8859-1')\n    \n    # Load user metadata (user demographics)\n    users = pd.read_csv(f'{data_dir}/users.dat', sep='::', header=None, engine='python',\n                        names=['user_id', 'gender', 'age', 'occupation', 'zip'], encoding='ISO-8859-1')\n    \n    # Load item metadata (movie genres)\n    movies = pd.read_csv(f'{data_dir}/movies.dat', sep='::', header=None, engine='python',\n                         names=['movie_id', 'title', 'genres'], encoding='ISO-8859-1')\n\n    # Encode user metadata features\n    gender_encoder = LabelEncoder()\n    users['gender'] = gender_encoder.fit_transform(users['gender'])\n\n    age_encoder = LabelEncoder()\n    users['age'] = age_encoder.fit_transform(users['age'])\n\n\n\n    occupation_encoder = LabelEncoder()\n    users['occupation'] = occupation_encoder.fit_transform(users['occupation'])\n\n    # Encode movie genres\n    genre_encoder = LabelEncoder()\n    movies['genres'] = movies['genres'].apply(lambda x: x.split('|')[0])  # Use the first genre as primary\n    movies['genres'] = genre_encoder.fit_transform(movies['genres'])\n\n    # Merge data\n    data = pd.merge(ratings, users, on='user_id')\n    data = pd.merge(data, movies, on='movie_id')\n\n    return data, len(users), len(movies), len(gender_encoder.classes_), len(age_encoder.classes_), \\\n           len(occupation_encoder.classes_), len(genre_encoder.classes_)\n\nclass MovieLensDataset(Dataset):\n    def __init__(self, dataframe):\n        self.data = dataframe\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        row = self.data.iloc[idx]\n        user_id = torch.tensor(row['user_id'], dtype=torch.long)\n        item_id = torch.tensor(row['movie_id'], dtype=torch.long)\n        rating = torch.tensor(row['rating'], dtype=torch.float)\n\n        # User metadata\n        gender = torch.tensor(row['gender'], dtype=torch.long)\n        age = torch.tensor(row['age'], dtype=torch.long)\n        occupation = torch.tensor(row['occupation'], dtype=torch.long)\n\n        # Item metadata\n        genre = torch.tensor(row['genres'], dtype=torch.long)\n\n        return user_id, item_id, gender, age, occupation, genre, rating\n\ndef get_dataloaders(data, batch_size=128, shuffle=True):\n    dataset = MovieLensDataset(data)\n    return DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T08:03:12.898713Z","iopub.execute_input":"2024-11-22T08:03:12.899138Z","iopub.status.idle":"2024-11-22T08:03:15.604494Z","shell.execute_reply.started":"2024-11-22T08:03:12.899095Z","shell.execute_reply":"2024-11-22T08:03:15.603327Z"}},"outputs":[],"execution_count":2},{"id":"657216d5-bf33-40a8-9932-7c6abca9ae00","cell_type":"code","source":"ratings = pd.read_csv(f'{data_dir}/u.data',sep = \"\\t\",header=None)\nratings.columns = ['user_id','movie_id','ratings','time_stamp']\nmovies = pd.read_csv(f'{data_dir}/u.item',sep = \"|\",header = None,encoding='ISO-8859-1')\nmovies.columns = ['movie_id', 'movie title' ,'release date','video release date', 'IMDb URL', 'unknown', 'Action', \n                'Adventure', 'Animation', 'Children\\'s', 'Comedy', 'Crime', 'Documentary', 'Drama', 'Fantasy', 'Film-Noir', \n                'Horror', 'Musical', 'Mystery', 'Romance', 'Sci-Fi', 'Thriller', 'War', 'Western']\nusers = pd.read_csv(f'{data_dir}/u.user',sep = \"|\",header = None,encoding='ISO-8859-1')\nusers.columns = ['user_id','age','gender','occupation','zipcode']\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T08:03:15.606561Z","iopub.execute_input":"2024-11-22T08:03:15.607107Z","iopub.status.idle":"2024-11-22T08:03:15.694307Z","shell.execute_reply.started":"2024-11-22T08:03:15.60707Z","shell.execute_reply":"2024-11-22T08:03:15.69277Z"}},"outputs":[],"execution_count":3},{"id":"74f48501-d24f-433a-ba7e-29c51d0903fd","cell_type":"code","source":"ratings.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T08:03:15.695926Z","iopub.execute_input":"2024-11-22T08:03:15.696448Z","iopub.status.idle":"2024-11-22T08:03:15.711828Z","shell.execute_reply.started":"2024-11-22T08:03:15.696396Z","shell.execute_reply":"2024-11-22T08:03:15.710446Z"}},"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 100000 entries, 0 to 99999\nData columns (total 4 columns):\n #   Column      Non-Null Count   Dtype\n---  ------      --------------   -----\n 0   user_id     100000 non-null  int64\n 1   movie_id    100000 non-null  int64\n 2   ratings     100000 non-null  int64\n 3   time_stamp  100000 non-null  int64\ndtypes: int64(4)\nmemory usage: 3.1 MB\n","output_type":"stream"}],"execution_count":4},{"id":"b5e64df4-6ed4-4a9a-aa2c-dad72a4fcfe1","cell_type":"code","source":"ratings.drop(columns = ['time_stamp'],inplace = True)\nusers.drop(columns = ['zipcode'],inplace = True)\nmovies.drop(columns = ['video release date', 'IMDb URL'],inplace = True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T08:03:15.713923Z","iopub.execute_input":"2024-11-22T08:03:15.714317Z","iopub.status.idle":"2024-11-22T08:03:15.732921Z","shell.execute_reply.started":"2024-11-22T08:03:15.714279Z","shell.execute_reply":"2024-11-22T08:03:15.731655Z"}},"outputs":[],"execution_count":5},{"id":"0db68571-05bc-4c28-a6b3-f1cfb40d85c2","cell_type":"code","source":"ratings.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T08:03:16.252215Z","iopub.execute_input":"2024-11-22T08:03:16.252756Z","iopub.status.idle":"2024-11-22T08:03:16.270785Z","shell.execute_reply.started":"2024-11-22T08:03:16.252626Z","shell.execute_reply":"2024-11-22T08:03:16.269094Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"   user_id  movie_id  ratings\n0      196       242        3\n1      186       302        3\n2       22       377        1\n3      244        51        2\n4      166       346        1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>movie_id</th>\n      <th>ratings</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>196</td>\n      <td>242</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>186</td>\n      <td>302</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>22</td>\n      <td>377</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>244</td>\n      <td>51</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>166</td>\n      <td>346</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":6},{"id":"3afc8185-f26c-4b69-9d2f-3e6779602b47","cell_type":"code","source":"movies.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T08:03:19.732189Z","iopub.execute_input":"2024-11-22T08:03:19.73262Z","iopub.status.idle":"2024-11-22T08:03:19.754861Z","shell.execute_reply.started":"2024-11-22T08:03:19.732582Z","shell.execute_reply":"2024-11-22T08:03:19.753357Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"   movie_id        movie title release date  unknown  Action  Adventure  \\\n0         1   Toy Story (1995)  01-Jan-1995        0       0          0   \n1         2   GoldenEye (1995)  01-Jan-1995        0       1          1   \n2         3  Four Rooms (1995)  01-Jan-1995        0       0          0   \n3         4  Get Shorty (1995)  01-Jan-1995        0       1          0   \n4         5     Copycat (1995)  01-Jan-1995        0       0          0   \n\n   Animation  Children's  Comedy  Crime  ...  Fantasy  Film-Noir  Horror  \\\n0          1           1       1      0  ...        0          0       0   \n1          0           0       0      0  ...        0          0       0   \n2          0           0       0      0  ...        0          0       0   \n3          0           0       1      0  ...        0          0       0   \n4          0           0       0      1  ...        0          0       0   \n\n   Musical  Mystery  Romance  Sci-Fi  Thriller  War  Western  \n0        0        0        0       0         0    0        0  \n1        0        0        0       0         1    0        0  \n2        0        0        0       0         1    0        0  \n3        0        0        0       0         0    0        0  \n4        0        0        0       0         1    0        0  \n\n[5 rows x 22 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>movie_id</th>\n      <th>movie title</th>\n      <th>release date</th>\n      <th>unknown</th>\n      <th>Action</th>\n      <th>Adventure</th>\n      <th>Animation</th>\n      <th>Children's</th>\n      <th>Comedy</th>\n      <th>Crime</th>\n      <th>...</th>\n      <th>Fantasy</th>\n      <th>Film-Noir</th>\n      <th>Horror</th>\n      <th>Musical</th>\n      <th>Mystery</th>\n      <th>Romance</th>\n      <th>Sci-Fi</th>\n      <th>Thriller</th>\n      <th>War</th>\n      <th>Western</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>Toy Story (1995)</td>\n      <td>01-Jan-1995</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>GoldenEye (1995)</td>\n      <td>01-Jan-1995</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>Four Rooms (1995)</td>\n      <td>01-Jan-1995</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>Get Shorty (1995)</td>\n      <td>01-Jan-1995</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>Copycat (1995)</td>\n      <td>01-Jan-1995</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 22 columns</p>\n</div>"},"metadata":{}}],"execution_count":7},{"id":"07b6f90b-5f5d-42e2-8a6c-f61362584208","cell_type":"code","source":"users.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T08:03:20.360488Z","iopub.execute_input":"2024-11-22T08:03:20.360887Z","iopub.status.idle":"2024-11-22T08:03:20.371863Z","shell.execute_reply.started":"2024-11-22T08:03:20.360849Z","shell.execute_reply":"2024-11-22T08:03:20.370629Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"   user_id  age gender  occupation\n0        1   24      M  technician\n1        2   53      F       other\n2        3   23      M      writer\n3        4   24      M  technician\n4        5   33      F       other","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>age</th>\n      <th>gender</th>\n      <th>occupation</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>24</td>\n      <td>M</td>\n      <td>technician</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>53</td>\n      <td>F</td>\n      <td>other</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>23</td>\n      <td>M</td>\n      <td>writer</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>24</td>\n      <td>M</td>\n      <td>technician</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>33</td>\n      <td>F</td>\n      <td>other</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":8},{"id":"40ef544d-5eee-4b1a-8732-acb09ba6f765","cell_type":"code","source":"## removing the movies that are not rated at all and also the users that were not participated in rating movies ###\nencoder = LabelEncoder()\nratings['movie_id']=encoder.fit_transform(ratings['movie_id'])\nrated_movies = set(encoder.classes_)\nn_original = len(movies)\nmovies = movies[movies['movie_id'].isin(rated_movies)].copy()\nn_after = len(movies)\nprint(\" {} movies are removed due to not being rated \".format(n_original-n_after))\n\nmovies['movie_id'] = encoder.transform(movies['movie_id'].values)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T07:52:12.507803Z","iopub.execute_input":"2024-11-22T07:52:12.508742Z","iopub.status.idle":"2024-11-22T07:52:12.530144Z","shell.execute_reply.started":"2024-11-22T07:52:12.508698Z","shell.execute_reply":"2024-11-22T07:52:12.528933Z"}},"outputs":[{"name":"stdout","text":" 0 movies are removed due to not being rated \n","output_type":"stream"}],"execution_count":24},{"id":"2cecb11b-539e-4b4a-8aa7-da269f789fab","cell_type":"code","source":"# same thing I will be doing for users that is users lazy to rate even a single movie \nu_encoder = LabelEncoder()\nratings['user_id'] = u_encoder.fit_transform(ratings['user_id'])\nn_original = len(users['user_id'])\nresponsible_users = set(u_encoder.classes_)\nusers = users[users['user_id'].isin(responsible_users)].copy()\nn_after = len(users['user_id'])\nprint(\"{} users have been removed under displinary actions\".format(n_original-n_after))\nusers['user_id'] = users['user_id']\nusers['user_id'] = u_encoder.transform(users['user_id'].values)\n\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T08:03:44.020292Z","iopub.execute_input":"2024-11-22T08:03:44.020709Z","iopub.status.idle":"2024-11-22T08:03:44.041384Z","shell.execute_reply.started":"2024-11-22T08:03:44.020674Z","shell.execute_reply":"2024-11-22T08:03:44.040188Z"}},"outputs":[{"name":"stdout","text":"1 users have been removed under displinary actions\n","output_type":"stream"}],"execution_count":10},{"id":"06ed6bad-d978-4d62-8b70-df4e51ab953a","cell_type":"code","source":"## Just to check all the three things once\nprint(ratings.head())\nprint(movies.head())\nprint(users.head())\nratings =ratings.sort_values(by = 'user_id').reset_index(drop = True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T08:03:55.242084Z","iopub.execute_input":"2024-11-22T08:03:55.242624Z","iopub.status.idle":"2024-11-22T08:03:55.27751Z","shell.execute_reply.started":"2024-11-22T08:03:55.242574Z","shell.execute_reply":"2024-11-22T08:03:55.276338Z"}},"outputs":[{"name":"stdout","text":"   user_id  movie_id  ratings\n0      195       242        3\n1      185       302        3\n2       21       377        1\n3      243        51        2\n4      165       346        1\n   movie_id        movie title release date  unknown  Action  Adventure  \\\n0         1   Toy Story (1995)  01-Jan-1995        0       0          0   \n1         2   GoldenEye (1995)  01-Jan-1995        0       1          1   \n2         3  Four Rooms (1995)  01-Jan-1995        0       0          0   \n3         4  Get Shorty (1995)  01-Jan-1995        0       1          0   \n4         5     Copycat (1995)  01-Jan-1995        0       0          0   \n\n   Animation  Children's  Comedy  Crime  ...  Fantasy  Film-Noir  Horror  \\\n0          1           1       1      0  ...        0          0       0   \n1          0           0       0      0  ...        0          0       0   \n2          0           0       0      0  ...        0          0       0   \n3          0           0       1      0  ...        0          0       0   \n4          0           0       0      1  ...        0          0       0   \n\n   Musical  Mystery  Romance  Sci-Fi  Thriller  War  Western  \n0        0        0        0       0         0    0        0  \n1        0        0        0       0         1    0        0  \n2        0        0        0       0         1    0        0  \n3        0        0        0       0         0    0        0  \n4        0        0        0       0         1    0        0  \n\n[5 rows x 22 columns]\n   user_id  age gender  occupation\n0        1   24      M  technician\n1        2   53      F       other\n2        3   23      M      writer\n3        4   24      M  technician\n4        5   33      F       other\n","output_type":"stream"}],"execution_count":11},{"id":"8bccbdfa-a39d-4e20-b98d-2161eaca6a8e","cell_type":"code","source":"# To make the data more clean and far away from real world \n# we will removies movies that are not rated atleast by 20 users\n# we will also fire users that are lazy to rate atleast 20 movies\n# just to make the calculations simple \n# we will skip this step once our model is ready to entre real world\nr_org = len(ratings) # before firing any lazy people or removing movies\ni = 0\nfor user in ratings['user_id'].unique():\n    if (len(ratings[ratings['user_id']==user])< 20):\n        i+=1\n        ratings.drop(ratings[ratings['user_id'] == user].index , inplace = True)\n        users.drop(users[users['user_id'] == user].index , inplace = True)\nprint(\"{} ratings have been removed as the {} users have been fired\".format(r_org- len(ratings),i))\nr_m = len(ratings)  ## remaing ratings after firing lazy users\nj = 0 \nfor movie in ratings['movie_id'].unique():\n    if(len(ratings[ratings['movie_id']==movie])<20):\n        j+=1\n        ratings.drop(ratings[ratings['movie_id']==movie].index,inplace = True)\n        movies.drop(movies[movies['movie_id'] == movie].index, inplace = True)\nprint(\"{} rating have been removied due to removing of {} less rated movies\".format(r_m - len(ratings), j))\n\nprint(\"IN TOTAL {} RATINGS CORRESPONDING TO {} USERS AND {} MOVIES HAVE BEEN REMOVED\".format(r_org-len(ratings),i,j))\n## IN THESE STEPS THERE ARE FEW MOVIES AND USERS THAT COULD HAVE STAYED BUT GOT REMOVED DUE TO RATING LESS RATED MOVIES OR RATED BY A LAZY USERS\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T08:12:23.345197Z","iopub.execute_input":"2024-11-22T08:12:23.345637Z","iopub.status.idle":"2024-11-22T08:12:28.809276Z","shell.execute_reply.started":"2024-11-22T08:12:23.3456Z","shell.execute_reply":"2024-11-22T08:12:28.808043Z"}},"outputs":[{"name":"stdout","text":"0 ratings have been removed as the 0 users have been fired\n5032 rating have been removied due to removing of 743 less rated movies\nIN TOTAL 5032 RATINGS CORRESPONDING TO 0 USERS AND 743 MOVIES HAVE BEEN REMOVED\n","output_type":"stream"}],"execution_count":20},{"id":"e677574c-4f44-412a-a85c-1f7f663d2a26","cell_type":"markdown","source":"# Data visualization ","metadata":{"execution":{"iopub.status.busy":"2024-11-22T08:13:17.821492Z","iopub.execute_input":"2024-11-22T08:13:17.821904Z","iopub.status.idle":"2024-11-22T08:13:17.829428Z","shell.execute_reply.started":"2024-11-22T08:13:17.821865Z","shell.execute_reply":"2024-11-22T08:13:17.827854Z"}}},{"id":"cb2299fb-1e94-4121-8f76-97a8211500ef","cell_type":"markdown","source":"This is a good way to know the pattrens in the data at hand \ndue to lazyness I am skipping this as of now , Later I will replace this writing with all the inside pattrens in the data\n","metadata":{}},{"id":"d37fc8b5-fcaf-4982-9e61-71e6a27e3e45","cell_type":"markdown","source":"## Data Loading","metadata":{}},{"id":"29c7c5dc-76f1-4b61-aff7-ac48a000016b","cell_type":"code","source":"def load_data(data_dir):\n    # Load ratings\n    ratings = pd.read_csv(f'{data_dir}/ratings.dat', sep='::', header=None, engine='python',\n                          names=['user_id', 'movie_id', 'rating', 'timestamp'], encoding='ISO-8859-1')\n    \n    # Load user metadata (user demographics)\n    users = pd.read_csv(f'{data_dir}/users.dat', sep='::', header=None, engine='python',\n                        names=['user_id', 'gender', 'age', 'occupation', 'zip'], encoding='ISO-8859-1')\n    \n    # Load item metadata (movie genres)\n    movies = pd.read_csv(f'{data_dir}/movies.dat', sep='::', header=None, engine='python',\n                         names=['movie_id', 'title', 'genres'], encoding='ISO-8859-1')\n\n    # Encode user metadata features\n    gender_encoder = LabelEncoder()\n    users['gender'] = gender_encoder.fit_transform(users['gender'])\n\n    age_encoder = LabelEncoder()\n    users['age'] = age_encoder.fit_transform(users['age'])\n\n\n\n    occupation_encoder = LabelEncoder()\n    users['occupation'] = occupation_encoder.fit_transform(users['occupation'])\n\n    # Encode movie genres\n    genre_encoder = LabelEncoder()\n    movies['genres'] = movies['genres'].apply(lambda x: x.split('|')[0])  # Use the first genre as primary\n    movies['genres'] = genre_encoder.fit_transform(movies['genres'])\n\n    # Merge data\n    data = pd.merge(ratings, users, on='user_id')\n    data = pd.merge(data, movies, on='movie_id')\n\n    return data, len(users), len(movies), len(gender_encoder.classes_), len(age_encoder.classes_), \\\n           len(occupation_encoder.classes_), len(genre_encoder.classes_)\n\nclass MovieLensDataset(Dataset):\n    def __init__(self, dataframe):\n        self.data = dataframe\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        row = self.data.iloc[idx]\n        user_id = torch.tensor(row['user_id'], dtype=torch.long)\n        item_id = torch.tensor(row['movie_id'], dtype=torch.long)\n        rating = torch.tensor(row['rating'], dtype=torch.float)\n\n        # User metadata\n        gender = torch.tensor(row['gender'], dtype=torch.long)\n        age = torch.tensor(row['age'], dtype=torch.long)\n        occupation = torch.tensor(row['occupation'], dtype=torch.long)\n\n        # Item metadata\n        genre = torch.tensor(row['genres'], dtype=torch.long)\n\n        return user_id, item_id, gender, age, occupation, genre, rating\n\ndef get_dataloaders(data, batch_size=128, shuffle=True):\n    dataset = MovieLensDataset(data)\n    return DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"85918561-99d7-46e0-847a-5b0e183a6a75","cell_type":"markdown","source":"## Model.py","metadata":{}},{"id":"e39fa735-42c8-4e0c-9ef9-456c6035e580","cell_type":"markdown","source":"","metadata":{}},{"id":"87f4f95c-02bf-460a-a36c-6cbcdf93f7db","cell_type":"code","source":"import torch\nimport torch.nn as nn\n\nclass MultiHeadSelfAttention(nn.Module):\n    def __init__(self, embed_dim, num_heads):\n        super(MultiHeadSelfAttention, self).__init__()\n        \n        self.multihead_attn = nn.MultiheadAttention(embed_dim, num_heads)\n\n    def forward(self, x):\n        attn_output, _ = self.multihead_attn(x, x, x)\n        return attn_output\n\nclass CrossAttentionLayer(nn.Module):\n    def __init__(self, embed_dim, num_heads):\n        super(CrossAttentionLayer, self).__init__()\n        self.multihead_attn = nn.MultiheadAttention(embed_dim, num_heads)\n\n    def forward(self, query, key, value):\n        attn_output, _ = self.multihead_attn(query, key, value)\n        return attn_output\n\nclass NCFModelWithMetadata(nn.Module):\n    def __init__(self, num_users, num_items, num_gender_features, num_age_features, num_occupation_features, num_genre_features, embed_dim, num_heads):\n        super(NCFModelWithMetadata, self).__init__()\n        # Embeddings for user and item IDs\n        self.user_embedding = nn.Embedding(num_users, embed_dim)\n        self.item_embedding = nn.Embedding(num_items, embed_dim)\n        \n        # Embeddings for user metadata (gender, age, occupation)\n        self.gender_embedding = nn.Embedding(num_gender_features, embed_dim)\n        self.age_embedding = nn.Embedding(num_age_features, embed_dim)\n        self.occupation_embedding = nn.Embedding(num_occupation_features, embed_dim)\n        \n        # Embedding for item metadata (genre)\n        self.genre_embedding = nn.Embedding(num_genre_features, embed_dim)\n\n        # Self-attention for user and item embeddings\n        self.user_self_attention = MultiHeadSelfAttention(embed_dim, num_heads)\n        self.item_self_attention = MultiHeadSelfAttention(embed_dim, num_heads)\n\n        # Cross-attention for interaction between user and item embeddings\n        self.cross_attention = CrossAttentionLayer(embed_dim, num_heads)\n\n        # Fully connected layers for final prediction\n        self.fc_layers = nn.Sequential(\n            nn.Linear(num_items, 128),  # Input size matches interaction_scores shape (batch_size, num_items)\n            nn.ReLU(),\n            nn.Dropout(0.3),\n            nn.Linear(128, 64),\n            nn.ReLU(),\n            nn.Linear(64, num_items)  # If outputting scores for num_items\n        )\n    def forward(self, user, item, gender, age, occupation, genre):\n        # Clamp input indices to be within the valid range\n        user = torch.clamp(user, 0, self.user_embedding.num_embeddings - 1)\n        item = torch.clamp(item, 0, self.item_embedding.num_embeddings - 1)\n        gender = torch.clamp(gender, 0, self.gender_embedding.num_embeddings - 1)\n        age = torch.clamp(age, 0, self.age_embedding.num_embeddings - 1)\n        occupation = torch.clamp(occupation, 0, self.occupation_embedding.num_embeddings - 1)\n        genre = torch.clamp(genre, 0, self.genre_embedding.num_embeddings - 1)\n    \n        # Embeddings for user and item IDs\n        user_emb = self.user_embedding(user)  # Shape: (batch_size, embed_dim)\n        item_emb = self.item_embedding(item)  # Shape: (batch_size, embed_dim)\n    \n        # Embeddings for user metadata\n        gender_emb = self.gender_embedding(gender)  # Shape: (batch_size, embed_dim)\n        age_emb = self.age_embedding(age)  # Shape: (batch_size, embed_dim)\n        occupation_emb = self.occupation_embedding(occupation)  # Shape: (batch_size, embed_dim)\n    \n        # Embedding for item metadata\n        genre_emb = self.genre_embedding(genre)  # Shape: (batch_size, embed_dim)\n    \n        # Combine user and item embeddings with their respective metadata\n        user_combined_emb = user_emb + gender_emb + age_emb + occupation_emb  # Shape: (batch_size, embed_dim)\n        item_combined_emb = item_emb + genre_emb  # Shape: (batch_size, embed_dim)\n    \n        # Apply self-attention to combined embeddings\n        user_self_attn = self.user_self_attention(user_combined_emb.unsqueeze(0))  # Shape: (1, batch_size, embed_dim)\n        item_self_attn = self.item_self_attention(item_combined_emb.unsqueeze(0))  # Shape: (1, batch_size, embed_dim)\n    \n        # Cross-attention between user and item embeddings\n        cross_attn_user = self.cross_attention(user_self_attn, item_self_attn, item_self_attn)  # Shape: (1, batch_size, embed_dim)\n        cross_attn_item = self.cross_attention(item_self_attn, user_self_attn, user_self_attn)  # Shape: (1, batch_size, embed_dim)\n    \n        # Prepare for interaction with all items\n        all_items_emb = self.item_embedding.weight  # Shape: (num_items, embed_dim)\n    \n        # Calculate interaction scores for all items for each user\n        # User representations repeated for all items\n        user_rep = cross_attn_user.squeeze(0).unsqueeze(1)  # Shape: (batch_size, 1, embed_dim)\n    \n        # Expand user_rep to match the shape of all_items_emb for element-wise multiplication\n        user_rep_expanded = user_rep.expand(-1, all_items_emb.size(0), -1)  # Shape: (batch_size, num_items, embed_dim)\n    \n        # Expand all_items_emb to have a batch dimension\n        all_items_emb_expanded = all_items_emb.unsqueeze(0).expand(user_rep_expanded.size(0), -1, -1)  # Shape: (batch_size, num_items, embed_dim)\n    \n        # Compute interaction scores using element-wise multiplication followed by summing over the last dimension\n        interaction_scores = (user_rep_expanded * all_items_emb_expanded).sum(dim=-1)  # Shape: (batch_size, num_items)\n    \n        # Feed-forward layers for final output\n        output = self.fc_layers(interaction_scores)  # Output shape: (batch_size, num_items)\n    \n        return output  # Return scores for all items for each user","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"68458c23-fa75-4e05-b28c-e9594b96b152","cell_type":"code","source":"\"\"\"\n#feed_forward ver-2\ndef forward(self, user, item, gender, age, occupation, genre):\n    # Clamp input indices to be within the valid range\n    user = torch.clamp(user, 0, self.user_embedding.num_embeddings - 1)\n    item = torch.clamp(item, 0, self.item_embedding.num_embeddings - 1)\n    gender = torch.clamp(gender, 0, self.gender_embedding.num_embeddings - 1)\n    age = torch.clamp(age, 0, self.age_embedding.num_embeddings - 1)\n    occupation = torch.clamp(occupation, 0, self.occupation_embedding.num_embeddings - 1)\n    genre = torch.clamp(genre, 0, self.genre_embedding.num_embeddings - 1)\n\n    # Embeddings for user and item IDs\n    # Shape: (batch_size, embed_dim)\n    user_emb = self.user_embedding(user)\n    item_emb = self.item_embedding(item)\n\n    # Embeddings for user metadata\n    # Shape: (batch_size, embed_dim)\n    gender_emb = self.gender_embedding(gender)\n    age_emb = self.age_embedding(age)\n    occupation_emb = self.occupation_embedding(occupation)\n\n    # Embedding for item metadata\n    # Shape: (batch_size, embed_dim)\n    genre_emb = self.genre_embedding(genre)\n\n    # Combine user and item embeddings with their respective metadata\n    # Adding metadata embeddings element-wise\n    # Shape: (batch_size, embed_dim)\n    user_combined_emb = user_emb + gender_emb + age_emb + occupation_emb\n    item_combined_emb = item_emb + genre_emb\n\n    # Apply self-attention to combined embeddings\n    # Input for self-attention needs to be (seq_len, batch_size, embed_dim)\n    # Reshape to (1, batch_size, embed_dim) for sequence length of 1\n    user_self_attn = self.user_self_attention(user_combined_emb.unsqueeze(0))\n    item_self_attn = self.item_self_attention(item_combined_emb.unsqueeze(0))\n\n    # Cross-attention between user and item embeddings\n    # Query, key, value shapes: (1, batch_size, embed_dim)\n    cross_attn_user = self.cross_attention(user_self_attn, item_self_attn, item_self_attn)\n    cross_attn_item = self.cross_attention(item_self_attn, user_self_attn, user_self_attn)\n\n    # Concatenate the attended representations along the embedding dimension\n    # Shape after squeeze: (batch_size, embed_dim)\n    # Concatenate along the last dimension: (batch_size, embed_dim * 2)\n    combined = torch.cat([cross_attn_user.squeeze(0), cross_attn_item.squeeze(0)], dim=-1)\n\n    # Feed-forward layers for prediction\n    # Shape: (batch_size, 1)\n    output = self.fc_layers(combined)\n\n    return output\n\"\"\"\"","metadata":{},"outputs":[],"execution_count":12},{"id":"985c727d-5cee-42e4-aabc-58bb62c61e9d","cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":13},{"id":"533bce38-fe69-408b-b3a0-62076b3f1c68","cell_type":"markdown","source":"## utils.py ","metadata":{}},{"id":"98a864b7-bc16-4827-91bc-f20f0092ba27","cell_type":"code","source":"import numpy as np\n\ndef hit_ratio(ranklist, gtItem):\n    \"\"\"Calculates Hit Ratio (HR).\"\"\"\n    return 1 if gtItem in ranklist else 0\n\ndef ndcg(ranklist, gtItem):\n    \"\"\"Calculates Normalized Discounted Cumulative Gain (NDCG).\"\"\"\n    if gtItem in ranklist:\n        index = ranklist.index(gtItem)\n        return np.log(2) / np.log(index + 2)\n    return 0\n\ndef mean_reciprocal_rank(ranklist, gtItem):\n    \"\"\"Calculates Mean Reciprocal Rank (MRR).\"\"\"\n    if gtItem in ranklist:\n        index = ranklist.index(gtItem)\n        return 1 / (index + 1)\n    return 0\n\ndef precision_at_k(ranklist, gtItem, k):\n    \"\"\"Calculates Precision@k.\"\"\"\n    ranklist = ranklist[:k]  # Truncate to top-k items\n    return 1 if gtItem in ranklist else 0\n\ndef evaluate_metrics(ranklist, gtItem, k):\n    \"\"\"\n    Evaluate multiple metrics: Hit Ratio, NDCG, MRR, Precision@k.\n    \n    Args:\n        ranklist: List of recommended item indices, ordered by relevance.\n        gtItem: Ground truth item index.\n        k: The number of top-k items for Precision@k.\n    \n    Returns:\n        Dictionary with HR, NDCG, MRR, and Precision@k.\n    \"\"\"\n    hr = hit_ratio(ranklist, gtItem)\n    ndcg_score = ndcg(ranklist, gtItem)\n    mrr_score = mean_reciprocal_rank(ranklist, gtItem)\n    precision_k = precision_at_k(ranklist, gtItem, k)\n\n    return {\n        'HR': hr,\n        'NDCG': ndcg_score,\n        'MRR': mrr_score,\n        'Precision@k': precision_k\n    }","metadata":{},"outputs":[],"execution_count":57},{"id":"fda079f4-18aa-484f-8626-1c5a5678462c","cell_type":"markdown","source":"##  train.py","metadata":{}},{"id":"1a615234-9702-4093-bca0-6fb9fd04a7e6","cell_type":"code","source":"\ndevice = torch.device(\"cpu\")","metadata":{},"outputs":[],"execution_count":82},{"id":"c94d5dc4-8fda-473b-af17-8ea86a16866e","cell_type":"code","source":"import torch.optim as optim\nfrom torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\nfrom ranger21 import Ranger21 as Ranger\n#from utils import evaluate_metrics\n\ndef train_model(model, train_loader, test_loader, num_epochs, switch_epoch, initial_lr, k):\n    model.to(device)\n    optimizer = optim.AdamW(model.parameters(), lr=initial_lr)\n    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2)\n\n    for epoch in range(num_epochs):\n        model.train()\n        total_loss = 0\n\n        for batch in train_loader:\n            user, item, gender, age, occupation, genre, rating = batch\n            user = user.to(device)\n            item = item.to(device)\n            gender = gender.to(device)\n            age = age.to(device)\n            occupation = occupation.to(device)\n            genre = genre.to(device)\n            rating = rating.to(device)\n\n            output = model(user, item, gender, age, occupation, genre).squeeze()\n            print(f\"Output shape: {output.shape}\")\n            print(f\"Item shape: {item.shape}\")\n            print(f\"Rating shape: {rating.shape}\")\n            actual_item_scores = output.gather(1, item.view(-1, 1)).squeeze()  # Shape: [128]\n            loss = F.mse_loss(actual_item_scores, rating.float())\n            # Calculate loss\n            #loss = F.mse_loss(output, rating)\n            total_loss += loss.item()\n\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n\n        # Switch optimizer at specified epoch\n        if epoch == switch_epoch:\n            optimizer = optim.Ranger(model.parameters(), lr=initial_lr)\n\n        scheduler.step()\n        \n        # Evaluate every few epochs\n        #if (epoch + 1) % 5 == 0 or epoch == num_epochs - 1:\n        eval_results = evaluate_model(model, test_loader, k)\n        print(f\"Epoch {epoch + 1}: Loss = {total_loss / len(train_loader):.4f}, \"\n                  f\"HR = {eval_results['HR']:.4f}, NDCG = {eval_results['NDCG']:.4f}, \"\n                  f\"MRR = {eval_results['MRR']:.4f}, Precision@{k} = {eval_results['Precision@k']:.4f}\")\n\ndef evaluate_model(model, test_loader, k):\n    model.eval()\n    all_hr, all_ndcg, all_mrr, all_precision_k = [], [], [], []\n\n    with torch.no_grad():\n        for batch in test_loader:\n            # Move all batch elements to device\n            user, item, gender, age, occupation, genre, rating = [x.to(device) for x in batch]\n            \n            # Pass the batch through the model\n            output = model(user, item, gender, age, occupation, genre).squeeze()\n\n            # Get top k predictions for each user in the batch\n            _, indices = torch.topk(output, k)  # indices shape should be [batch_size, k]\n            predicted_items = indices.cpu().numpy()  # Shape: [batch_size, k]\n            print(f\"Shape of predicted_items: {predicted_items.shape}\")\n            print(f\"Shape of indices: {indices.shape}\")\n            actual_items = item.cpu().numpy()  # Shape: [batch_size]\n            \n            # Loop through each user in the batch\n            for i in range(len(user)):  # Iterate through the batch\n                actual_item = actual_items[i]  # Actual item for user i\n                predicted = predicted_items[i]  # Top-k predicted items for user i\n                \n                print(f\"actual_item: {actual_item}, type: {type(actual_item)}\")\n                print(f\"predicted: {predicted}, type: {type(predicted)}, predicted shape: {predicted.shape}\")\n                \n                # Calculate metrics for this user\n                hr = calculate_hit_rate(actual_item, predicted)\n                ndcg = calculate_ndcg(actual_item, predicted)\n                mrr = calculate_mrr(actual_item, predicted)\n                precision_k = calculate_precision_at_k(actual_item, predicted, k)\n\n                # Append metrics\n                all_hr.append(hr)\n                all_ndcg.append(ndcg)\n                all_mrr.append(mrr)\n                all_precision_k.append(precision_k)\n\n    # Calculate average metrics across the batch\n    avg_hr = sum(all_hr) / len(all_hr)\n    avg_ndcg = sum(all_ndcg) / len(all_ndcg)\n    avg_mrr = sum(all_mrr) / len(all_mrr)\n    avg_precision_k = sum(all_precision_k) / len(all_precision_k)\n\n    return {'HR': avg_hr, 'NDCG': avg_ndcg, 'MRR': avg_mrr, 'Precision@k': avg_precision_k}\n\n# Metrics calculations for individual user-item pairs\ndef calculate_hit_rate(actual, predicted):\n    return 1 if actual in predicted else 0\n\ndef calculate_ndcg(actual, predicted):\n    if actual in predicted:\n        idx = list(predicted).index(actual)\n        return 1.0 / (torch.log2(torch.tensor(idx + 2).float()))\n    return 0.0\n\ndef calculate_mrr(actual, predicted):\n    if actual in predicted:\n        idx = list(predicted).index(actual)\n        return 1.0 / (idx + 1)\n    return 0.0\n\ndef calculate_precision_at_k(actual, predicted, k):\n    return int(actual in predicted[:k]) / k\n","metadata":{},"outputs":[],"execution_count":83},{"id":"82fadf0e-3e90-476c-82e8-ab1897122bde","cell_type":"markdown","source":"## Main.py","metadata":{}},{"id":"dc580a83-b752-45ad-a5ab-42542d2e3326","cell_type":"code","source":"import torch\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader\nfrom sklearn.model_selection import train_test_split\n#import os\n#os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n\ndef main():\n    data_dir = '/kaggle/input/movielens-100k-small-dataset'\n    data, num_users, num_items, num_gender_features, num_age_features, num_occupation_features, num_genre_features = load_data(data_dir)\n    \n    # Split the data into train and test sets\n    train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n    \n    train_loader = get_dataloaders(train_data, batch_size=128)\n    test_loader = get_dataloaders(test_data, batch_size=128)\n    train_items = set(train_data['movie_id'].values)\n    test_items = set(test_data['movie_id'].values)\n    print(\"Unique items in training set:\", len(train_items))\n    print(\"Unique items in test set:\", len(test_items))\n    print(\"Items in test set not in training set:\", len(test_items - train_items))\n    # Initialize the model\n    embed_dim = 128  # Adjust as necessary\n    num_heads = 4   # Adjust as necessary\n    model = NCFModelWithMetadata(num_users, num_items, num_gender_features, num_age_features, num_occupation_features, num_genre_features, embed_dim, num_heads)\n\n    # Train the model\n    num_epochs = 50\n    switch_epoch = 30  # Change optimizer after this epoch\n    initial_lr = 1e-3\n    k = 10  # For Precision@k\n\n    train_model(model, train_loader, test_loader, num_epochs, switch_epoch, initial_lr, k)\n\nif __name__ == '__main__':\n    main()","metadata":{"scrolled":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Output shape: torch.Size([128, 3883])","Item shape: torch.Size([128])","Rating shape: torch.Size([128])"]},{"ename":"RuntimeError","evalue":"index 3952 is out of bounds for dimension 1 with size 3883","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","Cell \u001b[1;32mIn[84], line 33\u001b[0m\u001b[0;32m     30\u001b[0m     train_model(model, train_loader, test_loader, num_epochs, switch_epoch, initial_lr, k)\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[1;32m---> 33\u001b[0m     main()","Cell \u001b[1;32mIn[84], line 30\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\u001b[0;32m     27\u001b[0m initial_lr \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1e-3\u001b[39m\u001b[0;32m     28\u001b[0m k \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m  \u001b[38;5;66;03m# For Precision@k\u001b[39;00m\u001b[1;32m---> 30\u001b[0m train_model(model, train_loader, test_loader, num_epochs, switch_epoch, initial_lr, k)","Cell \u001b[1;32mIn[83], line 29\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, train_loader, test_loader, num_epochs, switch_epoch, initial_lr, k)\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mItem shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mitem\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\u001b[0;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRating shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrating\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\u001b[1;32m---> 29\u001b[0m actual_item_scores \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mgather(\u001b[38;5;241m1\u001b[39m, item\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39msqueeze()  \u001b[38;5;66;03m# Shape: [128]\u001b[39;00m\u001b[0;32m     30\u001b[0m loss \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mmse_loss(actual_item_scores, rating\u001b[38;5;241m.\u001b[39mfloat())\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# Calculate loss\u001b[39;00m\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m#loss = F.mse_loss(output, rating)\u001b[39;00m","\u001b[1;31mRuntimeError\u001b[0m: index 3952 is out of bounds for dimension 1 with size 3883"]}],"execution_count":84},{"id":"e59d09d8-24e4-48b8-94c1-73a331023800","cell_type":"markdown","source":"## Just Back up functions","metadata":{"jp-MarkdownHeadingCollapsed":true}},{"id":"104bd448-c6b8-4065-a9f2-aa5e8ddf0425","cell_type":"code","source":"\n\n# Set device\n#device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ndevice = torch.device(\"cpu\")\n\ndef evaluate_model(model, test_loader, k):\n    model.eval()\n    metrics = {'HR': [], 'NDCG': [], 'MRR': [], 'Precision@k': []}\n\n    with torch.no_grad():\n        for batch in test_loader:\n            user, item, gtItem = batch\n            scores = model(user, item)\n            _, ranklist = torch.topk(scores, k=k)\n\n            metric_results = evaluate_metrics(ranklist.tolist(), gtItem.item(), k)\n            for key in metrics:\n                metrics[key].append(metric_results[key])\n\n    # Compute average values of each metric\n    averaged_metrics = {key: np.mean(metrics[key]) for key in metrics}\n    return averaged_metrics\n\n\ndef train_model(model, train_loader, test_loader, num_epochs, switch_epoch, initial_lr, k):\n    model.to(device)\n    optimizer = optim.AdamW(model.parameters(), lr=initial_lr)\n    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2)\n\n    for epoch in range(num_epochs):\n        model.train()\n        total_loss = 0\n\n        for batch in train_loader:\n            user, item, gender, age, occupation, genre, rating = batch\n            user = user.to(device)\n            item = item.to(device)\n            gender = gender.to(device)\n            age = age.to(device)\n            occupation = occupation.to(device)\n            genre = genre.to(device)\n            rating = rating.to(device)\n\n            output = model(user, item, gender, age, occupation, genre).squeeze()\n\n            # Calculate loss\n            loss = F.mse_loss(output, rating)\n            total_loss += loss.item()\n\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            \n        # Switch optimizer at specified epoch\n        if epoch == switch_epoch:\n            optimizer = optim.Ranger(model.parameters(), lr=initial_lr)\n\n        scheduler.step()\n        \n        # Evaluate every few epochs\n        #if (epoch + 1) % 5 == 0 or epoch == num_epochs - 1:\n        eval_results = evaluate_model(model, test_loader, k)\n        print(f\"Epoch {epoch + 1}: Loss = {total_loss / len(train_loader):.4f}, \"\n                  f\"HR = {eval_results['HR']:.4f}, NDCG = {eval_results['NDCG']:.4f}, \"\n                  f\"MRR = {eval_results['MRR']:.4f}, Precision@{k} = {eval_results['Precision@k']:.4f}\")\n\ndef forward(self, user, item, gender, age, occupation, genre):\n    # User embedding\n    user_emb = self.user_embedding(user)  # Shape: [batch_size, user_embedding_size]\n    # Item embedding\n    item_emb = self.item_embedding(item)  # Shape: [batch_size, item_embedding_size]\n\n    # Pass through multi-head and cross-attention layers\n    cross_attn_user = self.cross_attention_user(user_emb, genre)  # Adjust output shape if needed\n    cross_attn_item = self.cross_attention_item(item_emb, genre)  # Adjust output shape if needed\n\n    # Concatenate the attention outputs\n    combined = torch.cat([cross_attn_user, cross_attn_item], dim=-1)  # Check resulting shape\n\n    # Ensure combined shape matches the input for fc_layers\n    expected_input_size = self.fc_layers[0].in_features\n    if combined.size(1) != expected_input_size:\n        # Adjust combined dimensions to match expected input size\n        combined = F.linear(combined, torch.randn(expected_input_size, combined.size(1), device=combined.device))\n\n    output = self.fc_layers(combined)\n    return output\n\n#feed_forward ver-2 ( working version)\ndef forward(self, user, item, gender, age, occupation, genre):\n        # Embeddings for user and item IDs\n        user_emb = torch.clamp(user, 0, self.user_embedding.num_embeddings - 1)\n        item_emb = torch.clamp(item, 0, self.item_embedding.num_embeddings - 1)\n        print(\"user_emb_shape1;\", user_emb.shape)\n        # Embeddings for user metadata\n        gender_emb = self.gender_embedding(gender).unsqueeze(0)  # Shape: (1, batch_size, embed_dim)\n        age_emb = self.age_embedding(age).unsqueeze(0)  # Shape: (1, batch_size, embed_dim)\n        occupation_emb = self.occupation_embedding(occupation).unsqueeze(0)  # Shape: (1, batch_size, embed_dim)\n\n        # Embedding for item metadata\n        genre_emb = self.genre_embedding(genre).unsqueeze(0)  # Shape: (1, batch_size, embed_dim)\n        print(\"genere_emb:\",genre_emb.shape) \n        # Combine user and item embeddings with their respective metadata\n        user_combined_emb = user_emb + gender_emb + age_emb + occupation_emb\n        item_combined_emb = item_emb + genre_emb\n\n        # Apply self-attention to combined embeddings\n        user_self_attn = self.user_self_attention(user_combined_emb)\n        item_self_attn = self.item_self_attention(item_combined_emb)\n\n        # Cross-attention between user and item embeddings\n        cross_attn_user = self.cross_attention(user_self_attn, item_self_attn, item_self_attn)\n        cross_attn_item = self.cross_attention(item_self_attn, user_self_attn, user_self_attn)\n\n        # Concatenate the attended representations\n        combined = torch.cat([cross_attn_user.squeeze(0), cross_attn_item.squeeze(0)], dim=-1)\n        print(\"User embedding shape:\", user_emb.shape)\n        print(\"Item embedding shape:\", item_emb.shape)\n        print(\"Cross attention user shape:\", cross_attn_user.shape)\n        print(\"Cross attention item shape:\", cross_attn_item.shape)\n        print(\"Combined shape:\", combined.shape)\n\n\n        combined = combined.view(combined.size(0), -1)\n        # Feed-forward layers\n        output = self.fc_layers(combined)\n\n        return output","metadata":{},"outputs":[],"execution_count":null},{"id":"413ae66d-59eb-49fb-8be3-4e26777f3001","cell_type":"code","source":"\"\"\"\ndef evaluate_model(model, test_loader, k):\n    model.eval()\n    all_hr, all_ndcg, all_mrr, all_precision_k = [], [], [], []\n\n    with torch.no_grad():\n        for batch in test_loader:\n            # Assuming batch contains user, item, and metadata like gender, age, etc.\n            user, item, gender, age, occupation, genre, rating = batch\n            \n            # Pass the batch through the model\n            output = model(\n                user.to(device), \n                item.to(device), \n                gender.to(device), \n                age.to(device), \n                occupation.to(device), \n                genre.to(device)\n            ).squeeze()\n\n            # Get top k predictions for each user in the batch\n            _, indices = torch.topk(output, k)\n            predicted_items = indices.cpu().numpy()  # Predicted items for the batch\n            actual_items = item.cpu().numpy()  # Actual ground truth items for the batch\n            print(f\"predicted_items: {predicted}, type: {type(predicted)}\")\n            # Loop through each user in the batch\n            for i in range(len(user)):\n                actual_item = actual_items[i]  # Actual item for user i\n                predicted = predicted_items[i]  # Top-k predicted items for user i\n                print(f\"actual_item: {actual_item}, type: {type(actual_item)}\")\n                print(f\"predicted: {predicted}, type: {type(predicted)}\")      \n                # Calculate metrics for this user\n                hr = calculate_hit_rate(actual_item, predicted)\n                ndcg = calculate_ndcg(actual_item, predicted)\n                mrr = calculate_mrr(actual_item, predicted)\n                precision_k = calculate_precision_at_k(actual_item, predicted, k)\n\n                # Append metrics\n                all_hr.append(hr)\n                all_ndcg.append(ndcg)\n                all_mrr.append(mrr)\n                all_precision_k.append(precision_k)\n\n    # Calculate average metrics across the batch\n    avg_hr = sum(all_hr) / len(all_hr)\n    avg_ndcg = sum(all_ndcg) / len(all_ndcg)\n    avg_mrr = sum(all_mrr) / len(all_mrr)\n    avg_precision_k = sum(all_precision_k) / len(all_precision_k)\n\n    return {'HR': avg_hr, 'NDCG': avg_ndcg, 'MRR': avg_mrr, 'Precision@k': avg_precision_k}\n\"\"\"","metadata":{},"outputs":[],"execution_count":null},{"id":"a78a2548-8c18-48d0-8083-976cd884aa8b","cell_type":"code","source":"import torch\n\n# Set device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Using device: cuda"]}],"execution_count":76},{"id":"3342b2db-2446-42b3-87b0-2dbd4c47777d","cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null}]}